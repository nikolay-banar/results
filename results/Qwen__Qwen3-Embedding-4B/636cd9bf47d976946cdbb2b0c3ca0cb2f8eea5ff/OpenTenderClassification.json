{
  "dataset_revision": "9af5657575a669dc18c7f897a67287ff7d1a0c65",
  "task_name": "OpenTenderClassification",
  "mteb_version": "2.8.8",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.592196,
            "f1": 0.56768,
            "f1_weighted": 0.567731,
            "precision": 0.598731,
            "precision_weighted": 0.598786,
            "recall": 0.592101,
            "recall_weighted": 0.592196,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.577258,
            "f1": 0.556616,
            "f1_weighted": 0.556586,
            "precision": 0.593442,
            "precision_weighted": 0.593455,
            "recall": 0.577264,
            "recall_weighted": 0.577258,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.583055,
            "f1": 0.555729,
            "f1_weighted": 0.555769,
            "precision": 0.576501,
            "precision_weighted": 0.576472,
            "recall": 0.582966,
            "recall_weighted": 0.583055,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.566332,
            "f1": 0.544311,
            "f1_weighted": 0.544348,
            "precision": 0.558293,
            "precision_weighted": 0.558295,
            "recall": 0.566305,
            "recall_weighted": 0.566332,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.58573,
            "f1": 0.570314,
            "f1_weighted": 0.570397,
            "precision": 0.583543,
            "precision_weighted": 0.583572,
            "recall": 0.5856,
            "recall_weighted": 0.58573,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.591304,
            "f1": 0.576599,
            "f1_weighted": 0.576557,
            "precision": 0.60764,
            "precision_weighted": 0.607597,
            "recall": 0.591311,
            "recall_weighted": 0.591304,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.589521,
            "f1": 0.571117,
            "f1_weighted": 0.571141,
            "precision": 0.593853,
            "precision_weighted": 0.59378,
            "recall": 0.589399,
            "recall_weighted": 0.589521,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.564103,
            "f1": 0.532014,
            "f1_weighted": 0.532053,
            "precision": 0.57865,
            "precision_weighted": 0.578664,
            "recall": 0.563965,
            "recall_weighted": 0.564103,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.560312,
            "f1": 0.535312,
            "f1_weighted": 0.535275,
            "precision": 0.563308,
            "precision_weighted": 0.563151,
            "recall": 0.560262,
            "recall_weighted": 0.560312,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.574805,
            "f1": 0.549598,
            "f1_weighted": 0.549635,
            "precision": 0.567861,
            "precision_weighted": 0.567912,
            "recall": 0.57473,
            "recall_weighted": 0.574805,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.578462,
        "f1": 0.555929,
        "f1_weighted": 0.555949,
        "precision": 0.582182,
        "precision_weighted": 0.582168,
        "recall": 0.57839,
        "recall_weighted": 0.578462,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.555929,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 116.42620086669922,
  "kg_co2_emissions": null
}